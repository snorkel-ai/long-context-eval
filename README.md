# Long Context Evaluation

## Benchmark for testing long context windows on your own data

### Tests

- Single Document QA
    - [ ] Retrieval accuracy versus document depth
    - [ ] Retrieval accuracy: Long context versus RAG accuracy
    - [ ] Hallucination indicator: When the document is not present in context

### Test details

TBD

### To-do
- [ ] Multiprocessing while running test
- [ ] Get a suitable baseline RAG pipeline
- [ ] Results and visualization